#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å•æ¨¡æ€æ¨¡å‹è®­ç»ƒè„šæœ¬
æ”¯æŒText-onlyå’ŒImage-onlyè®­ç»ƒï¼Œç”¨äºæ¶ˆèå®éªŒ
"""

import os
import sys
import yaml
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import gc
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.text_encoder import TextEncoder
from models.image_encoder import ImageEncoder
from data.dataloader import MultimodalDataset
from utils.metrics import AverageMeter


class EarlyStopping:
    """Early Stoppingå·¥å…·"""
    
    def __init__(self, patience=5, min_delta=0.001, mode='max'):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        
    def __call__(self, score):
        if self.best_score is None:
            self.best_score = score
            return False
        
        if self.mode == 'max':
            if score > self.best_score + self.min_delta:
                self.best_score = score
                self.counter = 0
                return False
            else:
                self.counter += 1
        else:
            if score < self.best_score - self.min_delta:
                self.best_score = score
                self.counter = 0
                return False
            else:
                self.counter += 1
        
        if self.counter >= self.patience:
            self.early_stop = True
            return True
        
        return False


def train_epoch(model, dataloader, criterion, optimizer, device, modality):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    losses = AverageMeter()
    accuracies = AverageMeter()
    
    pbar = tqdm(dataloader, desc='Training')
    for batch in pbar:
        text_input = {k: v.to(device) for k, v in batch['text'].items()}
        images = batch['image'].to(device)
        labels = batch['label'].to(device)
        batch_size = images.size(0)
        
        # æ ¹æ®æ¨¡æ€é€‰æ‹©è¾“å…¥
        if modality == 'text':
            logits = model(text_input['input_ids'], text_input['attention_mask'])
        else:  # image
            logits = model(images)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(logits, labels)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # è®¡ç®—å‡†ç¡®ç‡
        _, preds = torch.max(logits, 1)
        correct = (preds == labels).sum().item()
        batch_acc = correct / batch_size
        
        # æ›´æ–°ç»Ÿè®¡
        losses.update(loss.item(), batch_size)
        accuracies.update(batch_acc, batch_size)
        
        pbar.set_postfix({
            'loss': f'{losses.avg:.4f}',
            'acc': f'{accuracies.avg:.4f}'
        })
        
        # æ¸…ç†å†…å­˜
        del logits, loss
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
    
    return losses.avg, accuracies.avg


def validate(model, dataloader, criterion, device, modality):
    """éªŒè¯"""
    model.eval()
    losses = AverageMeter()
    accuracies = AverageMeter()
    
    with torch.no_grad():
        pbar = tqdm(dataloader, desc='Validation')
        for batch in pbar:
            text_input = {k: v.to(device) for k, v in batch['text'].items()}
            images = batch['image'].to(device)
            labels = batch['label'].to(device)
            batch_size = images.size(0)
            
            # æ ¹æ®æ¨¡æ€é€‰æ‹©è¾“å…¥
            if modality == 'text':
                logits = model(text_input['input_ids'], text_input['attention_mask'])
            else:  # image
                logits = model(images)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(logits, labels)
            
            # è®¡ç®—å‡†ç¡®ç‡
            _, preds = torch.max(logits, 1)
            correct = (preds == labels).sum().item()
            batch_acc = correct / batch_size
            
            # æ›´æ–°ç»Ÿè®¡
            losses.update(loss.item(), batch_size)
            accuracies.update(batch_acc, batch_size)
            
            pbar.set_postfix({
                'loss': f'{losses.avg:.4f}',
                'acc': f'{accuracies.avg:.4f}'
            })
    
    return losses.avg, accuracies.avg


def main():
    parser = argparse.ArgumentParser(description='Train single-modal model')
    parser.add_argument('--config', type=str, required=True, help='Path to config file')
    parser.add_argument('--resume', type=str, default=None, help='Resume from checkpoint')
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(config['seed'])
    
    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    modality = config['modality']  # 'text' or 'image'
    if modality == 'text':
        model = TextEncoder(
            model_name=config['text_model'],
            num_classes=config['num_classes'],
            dropout=config['dropout']
        )
        print(f"âœ… Created Text-only model: {config['text_model']}")
    else:
        model = ImageEncoder(
            model_name=config['image_model'],
            num_classes=config['num_classes'],
            pretrained=config['pretrained'],
            dropout=config['dropout']
        )
        print(f"âœ… Created Image-only model: {config['image_model']}")
    
    model = model.to(device)
    
    # ä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡ç­–ç•¥ï¼ˆæ— éœ€å†»ç»“backboneï¼‰
    print("ğŸ¯ ä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡: backboneå¾®è°ƒ(1e-5), projection+classifierè®­ç»ƒ(1e-3)")
    
    # æ•°æ®åŠ è½½
    train_dataset = MultimodalDataset(
        csv_file=config['train_file'],
        data_dir=config['data_dir'],
        text_model=config.get('text_model', 'roberta-base'),
        max_text_length=config['max_text_length'],
        image_size=config['image_size'],
        augment=config['augment']
    )
    
    val_dataset = MultimodalDataset(
        csv_file=config['val_file'],
        data_dir=config['data_dir'],
        text_model=config.get('text_model', 'roberta-base'),
        max_text_length=config['max_text_length'],
        image_size=config['image_size'],
        augment=False
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config['num_workers']
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers']
    )
    
    print(f"ğŸ“Š Train: {len(train_dataset)} samples, Val: {len(val_dataset)} samples")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ï¼ˆåˆ†å±‚å­¦ä¹ ç‡ï¼‰
    # å‚æ•°åˆ†ç»„ï¼šbackboneç”¨å°å­¦ä¹ ç‡å¾®è°ƒï¼Œprojectionå’Œclassifierç”¨å¤§å­¦ä¹ ç‡
    param_groups = [
        {'params': model.encoder.parameters(), 'lr': config['backbone_lr']},
        {'params': model.projection.parameters(), 'lr': config['projection_lr']},
        {'params': model.classifier.parameters(), 'lr': config['classifier_lr']}
    ]
    
    optimizer = optim.AdamW(
        param_groups,
        weight_decay=config['weight_decay']
    )
    
    criterion = nn.CrossEntropyLoss()
    
    print(f"ğŸ“Š å­¦ä¹ ç‡é…ç½®: backbone={config['backbone_lr']}, projection={config['projection_lr']}, classifier={config['classifier_lr']}")
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config['epochs']
    )
    
    # TensorBoard
    log_dir = config['log_dir']
    os.makedirs(log_dir, exist_ok=True)
    writer = SummaryWriter(log_dir)
    
    # æ£€æŸ¥ç‚¹ç›®å½•
    checkpoint_dir = config['checkpoint_dir']
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # Early Stopping
    early_stopping = None
    if config.get('early_stopping', {}).get('enabled', False):
        early_stopping = EarlyStopping(
            patience=config['early_stopping']['patience'],
            min_delta=config['early_stopping']['min_delta'],
            mode='max'
        )
        print(f"ğŸ“‰ Early stopping enabled: patience={early_stopping.patience}")
    
    # Resume from checkpoint
    start_epoch = 0
    if args.resume:
        checkpoint = torch.load(args.resume, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        print(f"âœ… Resumed from epoch {start_epoch}")
    
    # è®­ç»ƒå¾ªç¯
    best_val_acc = 0.0
    
    for epoch in range(start_epoch, config['epochs']):
        print(f"\n{'='*60}")
        print(f"Epoch {epoch+1}/{config['epochs']}")
        print(f"{'='*60}")
        
        # è®­ç»ƒ
        train_loss, train_acc = train_epoch(
            model, train_loader, criterion, optimizer, device, modality
        )
        
        # éªŒè¯
        val_loss, val_acc = validate(
            model, val_loader, criterion, device, modality
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # è®°å½•åˆ°TensorBoard
        writer.add_scalar('Loss/train', train_loss, epoch)
        writer.add_scalar('Loss/val', val_loss, epoch)
        writer.add_scalar('Accuracy/train', train_acc, epoch)
        writer.add_scalar('Accuracy/val', val_acc, epoch)
        writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)
        
        print(f"\nğŸ“Š Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")
        print(f"ğŸ“Š Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'val_loss': val_loss,
            }, checkpoint_path)
            print(f"ğŸ’¾ Saved best model (acc: {val_acc:.4f})")
        
        # ä¿å­˜æœ€æ–°checkpoint
        latest_path = os.path.join(checkpoint_dir, f'epoch_{epoch}.pth')
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_acc': val_acc,
            'val_loss': val_loss,
        }, latest_path)
        
        # Early Stoppingæ£€æŸ¥
        if early_stopping:
            if early_stopping(val_acc):
                print(f"ğŸ›‘ Early stopping triggered at epoch {epoch+1}")
                print(f"   Best val acc: {early_stopping.best_score:.4f}")
                break
        
        # å†…å­˜æ¸…ç†
        gc.collect()
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
    
    writer.close()
    print(f"\nâœ… Training completed! Best val acc: {best_val_acc:.4f}")


if __name__ == '__main__':
    main()
