# CLIP Fusion配置文件

# 模型配置
fusion_type: 'clip'
clip_model: 'openai/clip-vit-base-patch32'
num_classes: 3
dropout: 0.3
freeze_clip: true  # 冻结CLIP参数

# 数据配置
data_dir: 'data'
train_file: 'data_split/train_split.csv'
val_file: 'data_split/val_split.csv'
max_text_length: 128  # 统一长度(CLIP内部会截断到77)
image_size: 224
augment: false  # 控制变量:关闭数据增强

# 训练配置 (控制变量)
batch_size: 32
num_workers: 4
epochs: 15
learning_rate: 5.0e-5  # 统一学习率
weight_decay: 0.01
seed: 42

# 其他配置
checkpoint_dir: 'checkpoints/clip_fusion'
log_dir: 'experiments/logs/clip_fusion'
